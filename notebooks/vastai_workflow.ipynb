{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN-LSS-Mamba vast.ai Workflow\n",
    "\n",
    "This notebook provides a complete workflow for training and evaluating the CAN-LSS-Mamba model on vast.ai.\n",
    "\n",
    "## Prerequisites\n",
    "- Repository cloned to `/workspace/can-lss-mamba`\n",
    "- Dataset uploaded to `/workspace/data/can-train-and-test-v1.5/set_01/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup Environment\n",
    "\n",
    "Run this cell once after cloning the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace/can-lss-mamba')\n",
    "\n",
    "# Run setup script\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Verify Environment\n",
    "\n",
    "Check that all dependencies are installed and GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Environment Verification\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"Scikit-learn Version: {sklearn_version}\")\n",
    "\n",
    "try:\n",
    "    import mamba_ssm\n",
    "    print(\"Mamba-SSM: Installed ✓\")\n",
    "except ImportError:\n",
    "    print(\"Mamba-SSM: Not installed ✗\")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    print(f\"WandB: {wandb.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"WandB: Not installed (optional)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Configure Experiment\n",
    "\n",
    "Set your experiment configuration and WandB credentials (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG_PATH = \"configs/vastai.yaml\"\n",
    "\n",
    "# WandB Configuration (optional)\n",
    "ENABLE_WANDB = False  # Set to True to enable WandB tracking\n",
    "WANDB_API_KEY = \"your_wandb_api_key_here\"  # Get from https://wandb.ai/authorize\n",
    "\n",
    "# Training Hyperparameters (optional overrides)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"CONFIG_PATH\"] = CONFIG_PATH\n",
    "os.environ[\"BATCH_SIZE\"] = str(BATCH_SIZE)\n",
    "os.environ[\"EPOCHS\"] = str(EPOCHS)\n",
    "os.environ[\"LR\"] = str(LEARNING_RATE)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    os.environ[\"WANDB_ENABLED\"] = \"true\"\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    print(\"✅ WandB enabled\")\n",
    "else:\n",
    "    os.environ[\"WANDB_ENABLED\"] = \"false\"\n",
    "    print(\"ℹ️  WandB disabled\")\n",
    "\n",
    "print(f\"Configuration: {CONFIG_PATH}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Preprocess Data\n",
    "\n",
    "Preprocess the raw CAN bus data into training/validation windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting preprocessing...\")\n",
    "!python preprocessing/CAN_preprocess.py\n",
    "print(\"\\n✅ Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Train Model\n",
    "\n",
    "Train the LSS-CAN-Mamba model with WandB tracking (if enabled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "!python train.py\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Evaluate Model\n",
    "\n",
    "Evaluate the trained model on all test scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting evaluation...\")\n",
    "!python evaluate.py\n",
    "print(\"\\n✅ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: View Results\n",
    "\n",
    "Display evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_file = \"/workspace/final_thesis_results_02.csv\"\n",
    "if os.path.exists(results_file):\n",
    "    df = pd.read_csv(results_file)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Evaluation Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Average F1 Score: {df['F1_Score'].mean():.4f}\")\n",
    "    print(f\"Average Accuracy: {df['Accuracy'].mean():.4f}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(f\"Results file not found: {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Download Checkpoints (Optional)\n",
    "\n",
    "Download model checkpoints to your local machine.\n",
    "\n",
    "**Note:** In vast.ai Jupyter, you can download files by:\n",
    "1. Navigate to `/workspace/checkpoints/set_01/` in the file browser\n",
    "2. Right-click on `lss_can_mamba_best.pth` → Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List checkpoint files\n",
    "checkpoint_dir = \"/workspace/checkpoints/set_01\"\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(f\"Checkpoint files in {checkpoint_dir}:\")\n",
    "    for f in os.listdir(checkpoint_dir):\n",
    "        file_path = os.path.join(checkpoint_dir, f)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"  - {f} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"Checkpoint directory not found: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **View Training Progress:** If WandB is enabled, visit: https://wandb.ai/YOUR_USERNAME/can-lss-mamba\n",
    "2. **Download Checkpoints:** Use the file browser to download model files\n",
    "3. **Re-run Training:** Modify hyperparameters in Cell 3 and re-run from Cell 5\n",
    "4. **Try Different Configs:** Change `CONFIG_PATH` to experiment with different settings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
